"""
Memory client utilities for OpenMemory.

This module provides functionality to initialize and manage the Mem0 memory client
with automatic configuration management.
"""

import hashlib
import json
import logging
import os
import sys

from app.database import SessionLocal
from app.models import Config as ConfigModel

# å¯¼å…¥ç»Ÿä¸€çš„è¶…æ—¶è¡¥ä¸ï¼ˆæ”¯æŒæ‰€æœ‰ embedderï¼Œé»˜è®¤ 60 ç§’ï¼‰
try:
    from app.utils.embedder_timeout_patch import patch_embedder_factory_timeout
    patch_embedder_factory_timeout()
except ImportError:
    pass

# å¯¼å…¥ Neo4j åŒå†™è¡¥ä¸ï¼ˆé€šè¿‡ HTTP API å®ç°åŒå†™ï¼Œä¸ä¿®æ”¹ bolt_proxyï¼‰
try:
    from app.utils.neo4j_dual_write_patch import patch_neo4j_graph_query
    # patch ä¼šåœ¨å¯¼å…¥æ—¶è‡ªåŠ¨åº”ç”¨
    pass
except ImportError:
    pass

from mem0 import Memory

_memory_client = None
_config_hash = None

# LLM é…ç½®ï¼ˆä¸ mem0 ä¸»åˆ†æ”¯ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ OPENAI_* ç¯å¢ƒå˜é‡ï¼‰
# æ³¨æ„ï¼šè™½ç„¶å˜é‡åä¸º OPENAI_*ï¼Œä½†å¯ä»¥ç”¨äºä»»ä½•å…¼å®¹ OpenAI API æ ¼å¼çš„æœåŠ¡
# ä¾‹å¦‚ï¼šOllama (http://localhost:11434/v1)ã€è‡ªå®šä¹‰ä»£ç†ã€DeepSeek ç­‰
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4")
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# Embedder é…ç½®ï¼ˆæ”¯æŒå¤šç§ providerï¼‰
EMBEDDER_PROVIDER = os.environ.get("EMBEDDER_PROVIDER", "openai")
EMBEDDER_MODEL = os.environ.get("EMBEDDER_MODEL")
EMBEDDER_BASE_URL = os.environ.get("EMBEDDER_BASE_URL")
EMBEDDER_API_KEY = os.environ.get("EMBEDDER_API_KEY")
EMBEDDER_DIMS = os.environ.get("EMBEDDER_DIMS")
EMBEDDER_TIMEOUT = os.environ.get("EMBEDDER_TIMEOUT")  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60 ç§’

# å¦‚æœä½¿ç”¨ Ollama çš„ OpenAI å…¼å®¹ APIï¼Œéœ€è¦æ·»åŠ  /v1 è·¯å¾„
# å¦‚æœä½¿ç”¨ Ollama åŸç”Ÿ APIï¼Œä¸éœ€è¦ /v1 è·¯å¾„
_embedder_base_url = EMBEDDER_BASE_URL or os.environ.get("OPENAI_EMBEDDING_MODEL_BASE_URL")
if _embedder_base_url and EMBEDDER_PROVIDER == "ollama" and not _embedder_base_url.endswith("/v1"):
    # å¦‚æœä½¿ç”¨ ollama providerï¼Œä½† base_url æ²¡æœ‰ /v1ï¼Œè¯´æ˜ä½¿ç”¨åŸç”Ÿ APIï¼Œä¸éœ€è¦ä¿®æ”¹
    # ä½†å¦‚æœ mem0 é€‰æ‹©äº† openai embedderï¼Œåˆ™éœ€è¦ /v1
    pass  # ä¿æŒåŸæ ·ï¼Œè®©åç»­é€»è¾‘å¤„ç†

OPENAI_EMBEDDING_MODEL_BASE_URL = _embedder_base_url or "https://api.openai.com/v1"
OPENAI_EMBEDDING_MODEL_API_KEY = EMBEDDER_API_KEY or os.environ.get(
    "OPENAI_EMBEDDING_MODEL_API_KEY", OPENAI_API_KEY
)
OPENAI_EMBEDDING_MODEL = EMBEDDER_MODEL or os.environ.get(
    "OPENAI_EMBEDDING_MODEL", "text-embedding-3-small"
)

# è®¡ç®— embedding ç»´åº¦ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
# 1. ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ EMBEDDER_DIMSï¼ˆæ¨èï¼‰
# 2. å…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_EMBEDDING_MODEL_DIMSï¼ˆå‘åå…¼å®¹ï¼‰
# 3. å¦‚æœéƒ½æ²¡æœ‰è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼ 1536
# æ³¨æ„ï¼šå¦‚æœç»´åº¦é…ç½®é”™è¯¯ï¼Œå‘é‡æ•°æ®åº“ä¼šåœ¨æ’å…¥/æœç´¢æ—¶ç›´æ¥æŠ¥é”™ï¼Œé”™è¯¯ä¿¡æ¯ä¼šåŒ…å«è¯¦ç»†çš„ç»´åº¦ä¿¡æ¯
OPENAI_EMBEDDING_MODEL_DIMS = int(
    EMBEDDER_DIMS 
    or os.environ.get("OPENAI_EMBEDDING_MODEL_DIMS", "1536")
)

# Graph Store é…ç½®ï¼ˆNeo4jï¼‰
# ä»£ç†æ¨¡å¼é…ç½®ï¼ˆæ¨èï¼Œä½¿ç”¨ graphs_proxyï¼‰
NEO4J_USE_PROXY = os.environ.get("NEO4J_USE_PROXY", "false").lower() == "true"
NEO4J_PROXY_URL = os.environ.get("NEO4J_PROXY_URL")
# ç›´è¿æ¨¡å¼é…ç½®ï¼ˆå¤‡é€‰ï¼‰
NEO4J_URL = os.environ.get("NEO4J_URL")
NEO4J_USERNAME = os.environ.get("NEO4J_USERNAME")
NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD")
# æ¸…ç†æ•°æ®åº“åç§°ï¼ˆå»é™¤å¯èƒ½çš„é¢å¤–å†…å®¹ï¼‰
_neo4j_database_raw = os.environ.get("NEO4J_DATABASE", "neo4j")
# å¦‚æœåŒ…å«å¼‚å¸¸å†…å®¹ï¼ˆå¦‚ç¯å¢ƒå˜é‡å®šä¹‰ï¼‰ï¼Œåªå–ç¬¬ä¸€éƒ¨åˆ†ï¼ˆåœ¨é‡åˆ°å¤§å†™å­—æ¯æˆ–ç­‰å·ä¹‹å‰ï¼‰
if _neo4j_database_raw and "NEO4J_URL" in _neo4j_database_raw:
    # å¦‚æœåŒ…å«ç¯å¢ƒå˜é‡å®šä¹‰ï¼Œåªå– "neo4j" éƒ¨åˆ†
    NEO4J_DATABASE = "neo4j"
elif _neo4j_database_raw:
    # å»é™¤ç©ºæ ¼å’Œæ¢è¡Œï¼Œåªå–ç¬¬ä¸€ä¸ªå•è¯
    NEO4J_DATABASE = _neo4j_database_raw.strip().split()[0] if _neo4j_database_raw.strip() else "neo4j"
else:
    NEO4J_DATABASE = "neo4j"


def _get_config_hash(config_dict):
    """Generate a hash of the config to detect changes."""
    config_str = json.dumps(config_dict, sort_keys=True)
    return hashlib.md5(config_str.encode()).hexdigest()


def reset_memory_client():
    """Reset the global memory client to force reinitialization with new config."""
    global _memory_client, _config_hash
    _memory_client = None
    _config_hash = None


def get_default_memory_config():
    """Get default memory client configuration with sensible defaults.
    
    ä¸ mem0 ä¸»å¹²ä¿æŒä¸€è‡´ï¼šä¸è®¾ç½® vector_storeï¼Œç”±æ•°æ®åº“é…ç½®æˆ– Pydantic é»˜è®¤å€¼å¤„ç†ã€‚
    å‚è€ƒ mem0/server/main.py çš„å®ç°æ–¹å¼ï¼šç›´æ¥æ„å»ºé…ç½®å­—å…¸ï¼Œæ˜ç¡®æŒ‡å®š providerã€‚
    """
    # æ³¨æ„ï¼šä¸è®¾ç½® vector_storeï¼Œè®©æ•°æ®åº“é…ç½®æˆ– Pydantic é»˜è®¤å€¼å¤„ç†ï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰

    # æ„å»º LLM é…ç½®ï¼ˆä¸ mem0 ä¸»åˆ†æ”¯ä¿æŒä¸€è‡´ï¼‰
    # ä½¿ç”¨ OPENAI_* ç¯å¢ƒå˜é‡ï¼Œæ”¯æŒæ‰€æœ‰å…¼å®¹ OpenAI API æ ¼å¼çš„æœåŠ¡
    # æ³¨æ„ï¼šprovider å›ºå®šä¸º "openai"ï¼Œå› ä¸ºæ‰€æœ‰å…¼å®¹ OpenAI API çš„æœåŠ¡éƒ½ä½¿ç”¨ openai provider
    llm_config = {
        "provider": "openai",
        "config": {
            "model": OPENAI_MODEL,
            "base_url": OPENAI_BASE_URL,
            "api_key": OPENAI_API_KEY,
            # temperatureã€max_tokensã€top_p ä½¿ç”¨ LLMConfig çš„é»˜è®¤å€¼
            # å¦‚æœéœ€è¦è‡ªå®šä¹‰ï¼Œè¯·åœ¨æ•°æ®åº“é…ç½®ä¸­è®¾ç½®
        },
    }

    # æ„å»º Embedder é…ç½®
    embedder_config = {
        "provider": EMBEDDER_PROVIDER,
        "config": {
            "api_key": EMBEDDER_API_KEY or OPENAI_EMBEDDING_MODEL_API_KEY,
            "model": EMBEDDER_MODEL or OPENAI_EMBEDDING_MODEL,
            "embedding_dims": OPENAI_EMBEDDING_MODEL_DIMS,
        },
    }
    
    # æ³¨æ„ï¼štimeout ä¸èƒ½ç›´æ¥ä¼ é€’ç»™ BaseEmbedderConfigï¼Œå› ä¸º BaseEmbedderConfig ä¸æ¥å— timeout å‚æ•°
    # timeout é…ç½®ä¼šåœ¨è¶…æ—¶è¡¥ä¸ä¸­ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œä¸éœ€è¦åœ¨è¿™é‡Œè®¾ç½®
    
    # æ ¹æ® provider è®¾ç½® base_url
    # æ³¨æ„ï¼šå¦‚æœ mem0 é€‰æ‹©äº† openai embedderï¼ˆå³ä½¿é…ç½®äº† ollama providerï¼‰ï¼Œ
    # éœ€è¦ä½¿ç”¨ openai_base_url å¹¶æ·»åŠ  /v1 è·¯å¾„ï¼ˆOllama çš„ OpenAI å…¼å®¹ APIï¼‰
    if EMBEDDER_BASE_URL:
        if EMBEDDER_PROVIDER == "openai":
            embedder_config["config"]["openai_base_url"] = EMBEDDER_BASE_URL
        elif EMBEDDER_PROVIDER == "ollama":
            embedder_config["config"]["ollama_base_url"] = EMBEDDER_BASE_URL
        else:
            embedder_config["config"]["base_url"] = EMBEDDER_BASE_URL
    elif EMBEDDER_PROVIDER == "openai":
        embedder_config["config"]["openai_base_url"] = OPENAI_EMBEDDING_MODEL_BASE_URL
    elif EMBEDDER_PROVIDER == "ollama":
        embedder_config["config"]["ollama_base_url"] = "http://localhost:11434"

    # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡º embedder é…ç½®
    logging.info("=" * 80)
    logging.info("ğŸ” Embedder é…ç½®ä¿¡æ¯:")
    logging.info(f"   Provider: {embedder_config.get('provider')}")
    logging.info(f"   Model: {embedder_config.get('config', {}).get('model')}")
    logging.info(f"   Base URL: {embedder_config.get('config', {}).get('ollama_base_url') or embedder_config.get('config', {}).get('openai_base_url')}")
    logging.info(f"   Embedding Dims: {embedder_config.get('config', {}).get('embedding_dims')}")
    logging.info(f"   Timeout: {embedder_config.get('config', {}).get('timeout', 'æœªè®¾ç½®')}")
    logging.info("=" * 80)

    # æ„å»º Graph Store é…ç½®ï¼ˆNeo4jï¼‰
    graph_store_config = None
    
    # Neo4j é…ç½®ç­–ç•¥ï¼š
    # 1. å¦‚æœå¯ç”¨äº†åŒå†™æ¨¡å¼ï¼ˆNEO4J_ENABLE_DUAL_WRITE=trueï¼‰ï¼Œä½¿ç”¨ HTTP API åŒå†™
    #    - mem0 ç›´æ¥è¿æ¥åˆ° Neo4jï¼ˆä½œä¸ºé™çº§å¤‡ç”¨ï¼‰
    #    - å†™æ“ä½œé€šè¿‡ HTTP API æ‰§è¡Œï¼ˆæ”¯æŒåŒå†™å’Œæ•…éšœè½¬ç§»ï¼‰
    # 2. å¦‚æœå¯ç”¨äº† Bolt ä»£ç†ï¼ˆNEO4J_BOLT_PROXY_URLï¼‰ï¼Œä½¿ç”¨ Bolt ä»£ç†
    # 3. å¦åˆ™ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼
    
    enable_dual_write = os.environ.get("NEO4J_ENABLE_DUAL_WRITE", "true").lower() == "true"
    bolt_proxy_url = os.environ.get("NEO4J_BOLT_PROXY_URL")  # ä¾‹å¦‚: bolt://localhost:7688
    
    if enable_dual_write and NEO4J_PROXY_URL:
        # åŒå†™æ¨¡å¼ï¼šmem0 ç›´æ¥è¿æ¥ Neo4jï¼ˆä½œä¸ºé™çº§å¤‡ç”¨ï¼‰ï¼Œå†™æ“ä½œé€šè¿‡ HTTP API åŒå†™
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™æ ¹æ®è¿è¡Œç¯å¢ƒé€‰æ‹©é»˜è®¤å€¼
        neo4j_url = os.environ.get("NEO4J_URL")
        if not neo4j_url:
            # æ£€æŸ¥æ˜¯å¦åœ¨ Docker ç¯å¢ƒä¸­ï¼ˆé€šè¿‡æ£€æŸ¥ /proc/self/cgroup æˆ–ç¯å¢ƒå˜é‡ï¼‰
            is_docker = os.path.exists("/.dockerenv") or os.environ.get("DOCKER_CONTAINER") == "true"
            if is_docker:
                neo4j_url = "bolt://neo4j_primary:7687"  # Docker å®¹å™¨åç§°
            else:
                neo4j_url = "bolt://localhost:7687"  # æœ¬åœ°ç¯å¢ƒ
        graph_store_config = {
            "provider": "neo4j",
            "config": {
                "url": neo4j_url,  # ç›´è¿ Neo4jï¼ˆé™çº§å¤‡ç”¨ï¼‰
                "username": NEO4J_USERNAME or "neo4j",
                "password": NEO4J_PASSWORD,
                "database": NEO4J_DATABASE,
            },
        }
        print(f"âœ… [GRAPH STORE] Auto-detected graph store: neo4j (åŒå†™æ¨¡å¼ - HTTP API)")
        print(f"   ç›´è¿åœ°å€ï¼ˆé™çº§å¤‡ç”¨ï¼‰: {neo4j_url}")
        print(f"   HTTP ä»£ç†åœ°å€ï¼ˆåŒå†™ï¼‰: {NEO4J_PROXY_URL}")
        print(f"   ç”¨æˆ·å: {NEO4J_USERNAME or 'neo4j'}")
        print(f"   æ•°æ®åº“: {NEO4J_DATABASE}")
        print(f"   ğŸ’¡ æç¤º: å†™æ“ä½œé€šè¿‡ HTTP API åŒå†™ï¼Œè¯»æ“ä½œå’Œé™çº§æ—¶ä½¿ç”¨ç›´è¿")
    elif bolt_proxy_url:
        # Bolt ä»£ç†æ¨¡å¼ï¼šé€šè¿‡ Bolt ä»£ç†è¿æ¥
        graph_store_config = {
            "provider": "neo4j",
            "config": {
                "url": bolt_proxy_url,  # Bolt ä»£ç†ç«¯å£
                "username": NEO4J_USERNAME or "neo4j",
                "password": NEO4J_PASSWORD,
                "database": NEO4J_DATABASE,
            },
        }
        print(f"âœ… [GRAPH STORE] Auto-detected graph store: neo4j (ä»£ç†æ¨¡å¼ - Bolt ä»£ç†)")
        print(f"   Bolt ä»£ç†åœ°å€: {bolt_proxy_url}")
        print(f"   HTTP ä»£ç†åœ°å€: {NEO4J_PROXY_URL or 'æœªé…ç½®'}")
        print(f"   ç”¨æˆ·å: {NEO4J_USERNAME or 'neo4j'}")
        print(f"   æ•°æ®åº“: {NEO4J_DATABASE}")
        print(f"   ğŸ’¡ æç¤º: é€šè¿‡ graphs_proxy Bolt ä»£ç†è¿æ¥ï¼Œæ”¯æŒåŒå†™å’Œæ•…éšœè½¬ç§»")
    elif NEO4J_USE_PROXY and NEO4J_PROXY_URL:
        # æ—§ç‰ˆä»£ç†æ¨¡å¼ï¼ˆå…¼å®¹æ€§ï¼‰
        neo4j_url = os.environ.get("NEO4J_URL", "bolt://neo4j_primary:7687")
        graph_store_config = {
            "provider": "neo4j",
            "config": {
                "url": neo4j_url,
                "username": NEO4J_USERNAME or "neo4j",
                "password": NEO4J_PASSWORD,
                "database": NEO4J_DATABASE,
            },
        }
        print(f"âš ï¸  [GRAPH STORE] ä»£ç†æ¨¡å¼å·²å¯ç”¨ï¼Œä½†æœªé…ç½®åŒå†™æˆ– Bolt ä»£ç†")
        print(f"   ä½¿ç”¨ç›´è¿æ¨¡å¼è¿æ¥åˆ° Neo4j: {neo4j_url}")
        print(f"   ğŸ’¡ æç¤º: å»ºè®®è®¾ç½® NEO4J_ENABLE_DUAL_WRITE=true å¯ç”¨åŒå†™æ¨¡å¼")
    # å¤‡é€‰ï¼šç›´è¿æ¨¡å¼ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰
    elif NEO4J_URL and NEO4J_USERNAME and NEO4J_PASSWORD:
        graph_store_config = {
            "provider": "neo4j",
            "config": {
                "url": NEO4J_URL,
                "username": NEO4J_USERNAME,
                "password": NEO4J_PASSWORD,
                "database": NEO4J_DATABASE,
            },
        }
        print(f"âœ… [GRAPH STORE] Auto-detected graph store: neo4j (ç›´è¿æ¨¡å¼)")
        print(f"   URL: {NEO4J_URL}")
        print(f"   Username: {NEO4J_USERNAME}")
        print(f"   Database: {NEO4J_DATABASE}")
    else:
        print("â„¹ï¸  [GRAPH STORE] Graph store æœªé…ç½®")
        if NEO4J_USE_PROXY and not NEO4J_PROXY_URL:
            print("   âš ï¸  å·²å¯ç”¨ä»£ç†æ¨¡å¼ä½†æœªé…ç½® NEO4J_PROXY_URL")
        elif not NEO4J_USE_PROXY and not NEO4J_URL:
            print("   âš ï¸  æœªé…ç½® NEO4J_URL æˆ– NEO4J_PROXY_URL")

    config_dict = {
        "llm": llm_config,
        "embedder": embedder_config,
        "version": "v1.1",
    }
    
    # åªæœ‰åœ¨é…ç½®äº† Neo4j æ—¶æ‰æ·»åŠ  graph_store
    if graph_store_config:
        config_dict["graph_store"] = graph_store_config
    
    # æ³¨æ„ï¼šä¸è®¾ç½® vector_storeï¼Œç”±æ•°æ®åº“é…ç½®æˆ– Pydantic é»˜è®¤å€¼å¤„ç†ï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰
    return config_dict


def _parse_environment_variables(config_dict):
    """
    Parse environment variables in config values.
    Converts 'env:VARIABLE_NAME' to actual environment variable values.
    """
    if isinstance(config_dict, dict):
        parsed_config = {}
        for key, value in config_dict.items():
            if isinstance(value, str) and value.startswith("env:"):
                env_var = value.split(":", 1)[1]
                env_value = os.environ.get(env_var)
                if env_value:
                    parsed_config[key] = env_value
                    print(f"Loaded {env_var} from environment for {key}")
                else:
                    print(
                        f"Warning: Environment variable {env_var} not found, keeping original value"
                    )
                    parsed_config[key] = value
            elif isinstance(value, dict):
                parsed_config[key] = _parse_environment_variables(value)
            else:
                parsed_config[key] = value
        return parsed_config
    return config_dict


def get_memory_client(custom_instructions: str = None):
    """
    Get or initialize the Mem0 client.

    Args:
        custom_instructions: Optional instructions for the memory project.

    Returns:
        Initialized Mem0 client instance or None if initialization fails.

    Raises:
        Exception: If required API keys are not set or critical configuration is missing.
    """
    global _memory_client, _config_hash

    try:
        # Start with default configuration
        config = get_default_memory_config()

        # Variable to track custom instructions
        db_custom_instructions = None

        # Load configuration from database
        try:
            db = SessionLocal()
            db_config = db.query(ConfigModel).filter(ConfigModel.key == "main").first()

            if db_config:
                json_config = db_config.value

                # Extract custom instructions from openmemory settings
                if (
                    "openmemory" in json_config
                    and "custom_instructions" in json_config["openmemory"]
                ):
                    db_custom_instructions = json_config["openmemory"][
                        "custom_instructions"
                    ]

                # Override defaults with configurations from the database
                # ä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼šæ•°æ®åº“é…ç½®ä¼˜å…ˆï¼Œç›´æ¥ä½¿ç”¨é…ç½®å­—å…¸ï¼Œç”± Pydantic éªŒè¯
                if "mem0" in json_config:
                    mem0_config = json_config["mem0"]

                    # Update LLM configuration if available
                    # æ•°æ®åº“é…ç½®ä¼˜å…ˆï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰
                    if "llm" in mem0_config and mem0_config["llm"] is not None:
                        config["llm"] = mem0_config["llm"]
                        provider = config["llm"].get("provider", "æœªæŒ‡å®š")
                        print(f"âœ… [CONFIG] ä½¿ç”¨æ•°æ®åº“ä¸­çš„ llm é…ç½® (provider: {provider})")

                    # Update Embedder configuration if available
                    # æ•°æ®åº“é…ç½®ä¼˜å…ˆï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰
                    if (
                        "embedder" in mem0_config
                        and mem0_config["embedder"] is not None
                    ):
                        config["embedder"] = mem0_config["embedder"]
                        provider = config["embedder"].get("provider", "æœªæŒ‡å®š")
                        print(f"âœ… [CONFIG] ä½¿ç”¨æ•°æ®åº“ä¸­çš„ embedder é…ç½® (provider: {provider})")

                    # Vector Store é…ç½®ï¼šæ•°æ®åº“é…ç½®ä¼˜å…ˆï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰
                    # mem0 ä¸»å¹²çš„é€»è¾‘ï¼šç›´æ¥ä½¿ç”¨é…ç½®å­—å…¸ä¸­çš„ vector_storeï¼Œç”± Pydantic éªŒè¯
                    if (
                        "vector_store" in mem0_config
                        and mem0_config["vector_store"] is not None
                    ):
                        config["vector_store"] = mem0_config["vector_store"]
                        provider = "æœªæŒ‡å®š"
                        if isinstance(mem0_config["vector_store"], dict):
                            provider = mem0_config["vector_store"].get("provider", "æœªæŒ‡å®š")
                        print(f"âœ… [CONFIG] ä½¿ç”¨æ•°æ®åº“ä¸­çš„ vector_store é…ç½® (provider: {provider})")
                    
                    # Graph Store é…ç½®ï¼šæ•°æ®åº“é…ç½®ä¼˜å…ˆï¼ˆä¸ mem0 ä¸»å¹²ä¸€è‡´ï¼‰
                    if (
                        "graph_store" in mem0_config
                        and mem0_config["graph_store"] is not None
                    ):
                        config["graph_store"] = mem0_config["graph_store"]
                        provider = "æœªæŒ‡å®š"
                        if isinstance(mem0_config["graph_store"], dict):
                            provider = mem0_config["graph_store"].get("provider", "æœªæŒ‡å®š")
                        print(f"âœ… [CONFIG] ä½¿ç”¨æ•°æ®åº“ä¸­çš„ graph_store é…ç½® (provider: {provider})")
            else:
                print("No configuration found in database, using defaults")

            db.close()

        except Exception as e:
            print(f"Warning: Error loading configuration from database: {e}")
            print("Using default configuration")
            # Continue with default configuration if database config can't be loaded

        # Use custom_instructions parameter first, then fall back to database value
        instructions_to_use = custom_instructions or db_custom_instructions
        if instructions_to_use:
            config["custom_fact_extraction_prompt"] = instructions_to_use

        # ALWAYS parse environment variables in the final config
        # This ensures that even default config values like "env:OPENAI_API_KEY" get parsed
        print("Parsing environment variables in final config...")
        config = _parse_environment_variables(config)

        # Check if config has changed by comparing hashes
        current_config_hash = _get_config_hash(config)

        # Only reinitialize if config changed or client doesn't exist
        if _memory_client is None or _config_hash != current_config_hash:
            print(f"ğŸ”„ [MEMORY CLIENT] Initializing memory client with config hash: {current_config_hash}")
            try:
                _memory_client = Memory.from_config(config_dict=config)
                _config_hash = current_config_hash
                
                # éªŒè¯ graph store çŠ¶æ€
                enable_graph = getattr(_memory_client, 'enable_graph', False)
                has_graph = getattr(_memory_client, 'graph', None) is not None
                
                print("âœ… [MEMORY CLIENT] Memory client initialized successfully")
                print(f"   enable_graph: {enable_graph}")
                print(f"   graph å®ä¾‹å­˜åœ¨: {has_graph}")
                
                if enable_graph and has_graph:
                    print("   âœ… Graph store å·²å¯ç”¨å¹¶åˆå§‹åŒ–æˆåŠŸ")
                elif enable_graph:
                    print("   âš ï¸  Graph store é…ç½®å·²å¯ç”¨ä½†å®ä¾‹æœªåˆ›å»º")
                else:
                    print("   â„¹ï¸  Graph store æœªå¯ç”¨")
                    
            except Exception as init_error:
                import traceback
                error_trace = traceback.format_exc()
                print(f"âŒ [MEMORY CLIENT] Failed to initialize memory client: {init_error}")
                print(f"   é”™è¯¯å †æ ˆ:\n{error_trace}")
                print("âš ï¸  Server will continue running with limited memory functionality")
                _memory_client = None
                _config_hash = None
                return None

        return _memory_client

    except Exception as e:
        print(f"Warning: Exception occurred while initializing memory client: {e}")
        print("Server will continue running with limited memory functionality")
        return None


def get_default_user_id():
    return "default_user"
